# -*- coding: utf-8 -*-
# app.py
import streamlit as st
import pandas as pd
import json
import io
import base64
import os
import re 
import pytz 
from google import genai
from google.genai.errors import APIError
import time 
from db import save_to_db, fetch_all_reports

# ===============================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API
# ===============================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyCH82HGwbNJxqjABAARHoi1lQfPoYL_j1I") 
MODEL_NAME = 'gemini-2.5-flash-preview-09-2025'

REPORT_FIELDS_ARABIC = [
    "Ø±Ù‚Ù… Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©",
    "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©",
    "Ø§Ù„Ù…Ù‡Ù†Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ",
    "Ø±Ù‚Ù… Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
    "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰",
    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©",
    "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©"  # ğŸ’¡ ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù‡Ù†Ø§
]

RESPONSE_SCHEMA = {
    "type": "OBJECT",
    "properties": {
        field: {"type": "STRING", "description": f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© Ù„Ù€: {field}"}
        for field in REPORT_FIELDS_ARABIC
    },
    "propertyOrdering": REPORT_FIELDS_ARABIC
}

DELALAT_MAPPING = {
    1: "ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹Ø§ØªØŒ Ø­ÙˆØ§Ù„Ø§Øª Ø³Ø­ÙˆØ¨Ø§Øª Ù…Ø´ØªØ±ÙŠØ§Øª) ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠÙ… Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ Ø§Ù„Ø³Ù†ÙˆÙŠ.",
    2: "ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø­Ø³Ø§Ø¨ Ø¹Ù…ÙŠÙ„ Ù…Ù‚ÙŠÙ… Ø§Ù„Ù‰ Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ.",
    3: "Ø­ÙˆØ§Ù„Ø§Øª ØµØ§Ø¯Ø±Ø© Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠÙ… Ø£Ø¬Ù†Ø¨ÙŠ Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø¯Ø§Ø¯ Ù…ØµØ±ÙˆÙØ§Øª ØªÙ†Ù… Ø¹Ù† Ø§Ù„Ù…ØªØ§Ø¬Ø±Ø© ÙÙŠÙ‡Ø§ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© Ø¨ÙŠØ¹Ù‡Ø§.",
    4: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ø§Øª Ø£Ø´Ø®Ø§Øµ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ù„Ø§ ØªØ±Ø¨Ø·Ù‡Ù… Ø¨Ù‡ ØºØ±Ø¶ Ø£Ùˆ Ø¹Ù„Ø§Ù‚Ø© Ø¹Ù…Ù„.",
    5: "Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª ØªØ­ÙˆÙŠÙ„ Ù…Ø§Ù„ÙŠØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ù„Ù‡ Ø£Ùˆ Ù„Ø£Ø´Ø®Ø§Øµ Ø¢Ø®Ø±ÙŠÙ† Ø¨Ù…Ø¨Ø§Ù„Øº Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ ÙˆÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ØµØ¯Ø±Ù‡Ø§ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ†.",
    6: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ù‚ÙŠÙ… Ø£Ùˆ Ù„Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠØ© Ø¨Ù…Ø¨Ø§Ù„Øº Ø¹Ø§Ù„ÙŠØ© ØªÙ†Ù… Ø¹Ù† Ø¥Ø¯Ø§Ø±Ø© Ù†Ø´Ø§Ø· ØªØ¬Ø§Ø±ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù…Ù„ÙƒØ©.",
    7: "Ø´Ø®Øµ Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹ Ø´ÙŠÙƒ Ø£Ùˆ ØµØ±Ù Ø´ÙŠÙƒ Ø£Ùˆ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø­ÙˆØ§Ù„Ù‡ Ù…Ø§Ù„ÙŠØ©) ÙˆÙ„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ (Ø¹Ù…ÙŠÙ„ Ø¹Ø§Ø¨Ø±).",
    8: "Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© ÙÙŠ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù…Ø¨ÙŠØ¹Ø§Øª Ù†Ù‚Ø§Ø· Ø¨ÙŠØ¹ØŒ ÙŠÙ„ÙŠÙ‡Ø§ ØªÙ†ÙÙŠØ° Ø­ÙˆØ§Ù„Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© Ø£Ùˆ Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ† Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø­Ø¨.",
    9: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ø£Ùˆ ØµØ§Ø¯Ø±Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù†Ø´Ø§Ø· Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ.",
    10: "ØªÙÙˆÙŠØ¶ Ø£Ø¬Ù†Ø¨ÙŠ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ Ø¹Ø§Ø¦Ø¯ Ù„ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ ÙˆØªÙ…ÙƒÙŠÙ†Ù‡ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ù…Ø¨Ø±Ø± Ø£Ùˆ ØºØ±Ø¶ ÙˆØ§Ø¶Ø­.",
    11: "ÙØªØ­ Ø¹Ø¯Ø© Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„ÙØ±ÙˆØ¹ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ù„Ù†ÙØ³ Ø§Ù„Ù†Ø´Ø§Ø· Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ø¶Ø­ Ø¨ÙŠÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§ØªØŒ Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„ÙØ±Ø¹ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚ÙŠÙ…."
}

SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ÙŠØ§Ù†Ø§Øª Ø¢Ù„ÙŠ (OCR/NLP). Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ© "
    "ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† JSON ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø¨Ø¯Ù‚Ø©. "
    "ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© ÙˆØ§Ù„Ù…ÙŠÙ„Ø§Ø¯ÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ **ØµÙŠØºØ© Ø±Ù‚Ù…ÙŠØ© Ù…ÙˆØ­Ø¯Ø©** 'Ø§Ù„Ø³Ù†Ø©/Ø§Ù„Ø´Ù‡Ø±/Ø§Ù„ÙŠÙˆÙ…' (YYYY/MM/DD) Ù…Ø«Ù„ '1445/06/21'. "
    "Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù…Ø·Ù„ÙˆØ¨ Ù„Ø¬Ù…ÙŠØ¹ Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ§Ù„ÙŠØ©: 'ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±', 'ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„', 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†', Ùˆ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰'. "
    "Ù‚Ù… Ø¨Ù†Ø³Ø® Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø®Ø±Ù‰ ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…Ø§ ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø¯ÙˆÙ† ØªÙ„Ø®ÙŠØµ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ©ØŒ Ø®Ø§ØµØ©Ù‹ ÙÙŠ Ø­Ù‚Ù„ 'Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡'. "
    "Ù‚Ù… Ø¨ØªØµØ­ÙŠØ­ Ø£ÙŠ Ø§Ù†Ø¹ÙƒØ§Ø³ Ø£Ùˆ ØªØ´ÙˆÙŠØ´ ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© 'ØºÙŠØ± Ù…ØªÙˆÙØ±' Ù„Ù„Ø­Ù‚ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©. "
    
    # ğŸ’¡ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø©
    "Ø¨Ø¹Ø¯ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù†Øµ Ø­Ù‚Ù„ 'Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡' ÙˆØ§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ø£Ù†Ø³Ø¨ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø¯Ù†Ø§Ù‡: "
    "1: ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹Ø§ØªØŒ Ø­ÙˆØ§Ù„Ø§Øª Ø³Ø­ÙˆØ¨Ø§Øª Ù…Ø´ØªØ±ÙŠØ§Øª) ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠÙ… Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ Ø§Ù„Ø³Ù†ÙˆÙŠ. "
    "2: ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø­Ø³Ø§Ø¨ Ø¹Ù…ÙŠÙ„ Ù…Ù‚ÙŠÙ… Ø§Ù„Ù‰ Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ. "
    "3: Ø­ÙˆØ§Ù„Ø§Øª ØµØ§Ø¯Ø±Ø© Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠÙ… Ø£Ø¬Ù†Ø¨ÙŠ Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø¯Ø§Ø¯ Ù…ØµØ±ÙˆÙØ§Øª ØªÙ†Ù… Ø¹Ù† Ø§Ù„Ù…ØªØ§Ø¬Ø±Ø© ÙÙŠÙ‡Ø§ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© Ø¨ÙŠØ¹Ù‡Ø§. "
    "4: Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ø§Øª Ø£Ø´Ø®Ø§Øµ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ù„Ø§ ØªØ±Ø¨Ø·Ù‡Ù… Ø¨Ù‡ ØºØ±Ø¶ Ø£Ùˆ Ø¹Ù„Ø§Ù‚Ø© Ø¹Ù…Ù„. "
    "5: Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª ØªØ­ÙˆÙŠÙ„ Ù…Ø§Ù„ÙŠØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ù„Ù‡ Ø£Ùˆ Ù„Ø£Ø´Ø®Ø§Øµ Ø¢Ø®Ø±ÙŠÙ† Ø¨Ù…Ø¨Ø§Ù„Øº Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ ÙˆÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ØµØ¯Ø±Ù‡Ø§ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ†. "
    "6: Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ù‚ÙŠÙ… Ø£Ùˆ Ù„Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠØ© Ø¨Ù…Ø¨Ø§Ù„Øº Ø¹Ø§Ù„ÙŠØ© ØªÙ†Ù… Ø¹Ù† Ø¥Ø¯Ø§Ø±Ø© Ù†Ø´Ø§Ø· ØªØ¬Ø§Ø±ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù…Ù„ÙƒØ©. "
    "7: Ø´Ø®Øµ Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹ Ø´ÙŠÙƒ Ø£Ùˆ ØµØ±Ù Ø´ÙŠÙƒ Ø£Ùˆ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø­ÙˆØ§Ù„Ù‡ Ù…Ø§Ù„ÙŠØ©) ÙˆÙ„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ (Ø¹Ù…ÙŠÙ„ Ø¹Ø§Ø¨Ø±). "
    "8: Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© ÙÙŠ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù…Ø¨ÙŠØ¹Ø§Øª Ù†Ù‚Ø§Ø· Ø¨ÙŠØ¹ØŒ ÙŠÙ„ÙŠÙ‡Ø§ ØªÙ†ÙÙŠØ° Ø­ÙˆØ§Ù„Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© Ø£Ùˆ Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ† Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø­Ø¨. "
    "9: Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ø£Ùˆ ØµØ§Ø¯Ø±Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù†Ø´Ø§Ø· Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ. "
    "10: ØªÙÙˆÙŠØ¶ Ø£Ø¬Ù†Ø¨ÙŠ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ Ø¹Ø§Ø¦Ø¯ Ù„ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ ÙˆØªÙ…ÙƒÙŠÙ†Ù‡ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ù…Ø¨Ø±Ø± Ø£Ùˆ ØºØ±Ø¶ ÙˆØ§Ø¶Ø­. "
    "11: ÙØªØ­ Ø¹Ø¯Ø© Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„ÙØ±ÙˆØ¹ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ù„Ù†ÙØ³ Ø§Ù„Ù†Ø´Ø§Ø· Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ø¶Ø­ Ø¨ÙŠÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§ØªØŒ Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„ÙØ±Ø¹ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚ÙŠÙ…. "
    "ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© ÙÙŠ Ø­Ù‚Ù„ 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' Ù‡ÙŠ **Ø§Ù„Ø±Ù‚Ù… ÙÙ‚Ø·** (Ù…Ø«Ù„: 1 Ø£Ùˆ 8 Ø£Ùˆ ØºÙŠØ± Ù…ØªÙˆÙØ±)."
)


# ===============================
# 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
# ===============================

def arabic_to_english_numbers(text):
    if not isinstance(text, str):
        return text
    arabic_map = {'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
                  'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'}
    return text.translate(str.maketrans(arabic_map))


def pre_process_data_fix_dates(data):
    """ØªØ¨Ø­Ø« Ø¹Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù…ØªÙ„Ø§ØµÙ‚Ø© (Ù…Ø«Ù„ 2022/10/052023/10/05) ÙˆØªÙ‚ÙˆÙ… Ø¨ÙØµÙ„Ù‡Ø§."""
    start_key = "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†"
    end_key = "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰"
    start_date_value = data.get(start_key, "")
    
    if start_date_value:
        clean_value = re.sub(r'[^\d]', '', start_date_value).strip()
        
        if len(clean_value) == 16:
            date1_clean = clean_value[:8] 
            date2_clean = clean_value[8:] 
            date1_formatted = f"{date1_clean[:4]}/{date1_clean[4:6]}/{date1_clean[6:]}"
            date2_formatted = f"{date2_clean[:4]}/{date2_clean[4:6]}/{date2_clean[6:]}"
            
            data[start_key] = date1_formatted
            if not data.get(end_key) or data.get(end_key).strip() in ['', 'ØºÙŠØ± Ù…ØªÙˆÙØ±']:
                 data[end_key] = date2_formatted
            
    return data


def check_for_suspicion(data):
    """ÙŠØ¶ÙŠÙ Ø¹Ù„Ø§Ù…Ø© 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' (ğŸ”´) Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§."""
    suspicion_indicator = ""
    
    # --- 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© ---
    date_fields = ["ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯"]
    for field in date_fields:
        date_val = data.get(field, "")
        try:
            date_str_en = arabic_to_english_numbers(str(date_val))
            parts = re.split(r'[/\-.]', date_str_en)
            if len(parts) == 3:
                year_str = re.sub(r'[^\d]', '', parts[0])
                year = int(year_str) if year_str else 0
                if year > 100 and year < 1400: 
                    suspicion_indicator += f"ğŸ”´ ({field}: Ø³Ù†Ø© ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ©) "
        except Exception:
            if str(date_val).strip() not in ['ØºÙŠØ± Ù…ØªÙˆÙØ±', '']:
                 suspicion_indicator += f"ğŸ”´ ({field}: ØµÙŠØºØ© ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø©) "
            pass
    
    # --- 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© ÙƒØµÙØ± ---
    financial_fields = ["Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"]
    for field in financial_fields:
        val = data.get(field, "")
        if str(val).strip() in ['0', '0.00', 'Ù ', 'Ù ,Ù Ù ']:
             suspicion_indicator += f"âš ï¸ ({field} = 0) "
             
    return suspicion_indicator.strip() or "âœ… Ø³Ù„ÙŠÙ…"

# ===============================
# 2. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ø¨Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ø­Ø¯Ø©)
# ===============================
def extract_financial_data(file_bytes, file_name, file_type):
    """ÙŠØ³ØªØ®Ù„Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù…Ø­Ø§ÙˆÙ„Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·."""
    if not GEMINI_API_KEY:
        return None
        
    try:
        client = genai.Client(api_key=GEMINI_API_KEY)
        mime_type = "application/pdf" if file_type=='pdf' else f"image/{'jpeg' if file_type=='jpg' else file_type}"
        content_parts = [
            "Ù‚Ù… Ø¨Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...",
            {"inlineData": {"data": base64.b64encode(file_bytes).decode('utf-8'), "mimeType": mime_type}}
        ]
        config = {
            "systemInstruction": SYSTEM_PROMPT,
            "responseMimeType": "application/json",
            "responseSchema": RESPONSE_SCHEMA
        }
        
        # ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        response = client.models.generate_content(model=MODEL_NAME, contents=content_parts, config=config)
            
        extracted_data = json.loads(response.text)
        
        extracted_data = pre_process_data_fix_dates(extracted_data) 
        
        extracted_data['Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù'] = file_name
        
        riyadh_tz = pytz.timezone('Asia/Riyadh')
        extracted_data['ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ'] = pd.Timestamp.now(tz=riyadh_tz).strftime("%Y-%m-%d %H:%M:%S")
        extracted_data['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª'] = check_for_suspicion(extracted_data) 
        
        return extracted_data 

    except APIError as e:
        st.error(f"âŒ ÙØ´Ù„Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…Ù† '{file_name}': {e}")
        return None 
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…Ù† '{file_name}': {e}")
        return None
    
# ===============================
# 3. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆÙ‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ===============================

def create_final_report_from_db(records, column_names):
    import xlsxwriter
    if not records: 
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§.")
        return None
        
    df = pd.DataFrame(records, columns=column_names)

    # ğŸ’¡ Ø¥Ø¶Ø§ÙØ© Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø© ÙÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    if 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' in df.columns:
        def get_delala_description(num):
            try:
                num_int = int(str(num).strip())
                return DELALAT_MAPPING.get(num_int, f"Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© {num} ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ")
            except:
                return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
                
        # ÙŠØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©
        df.insert(df.columns.get_loc('Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©') + 1, 'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©', df['Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©'].apply(get_delala_description))

    # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ³Ù„Ø³Ù„
    df.insert(0, '#', range(1, len(df) + 1))
    
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    
    sheet_name = 'Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ' 
    
    df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    workbook, worksheet = writer.book, writer.sheets[sheet_name]
    worksheet.right_to_left()
    col_format = workbook.add_format({'text_wrap': True, 'align': 'right', 'valign': 'top'})
    
    for i, col_name in enumerate(df.columns):
        if col_name in ['Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡', 'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©']:
            worksheet.set_column(i, i, 120, col_format)
        else:
            width = 25 if col_name in ["Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] else 18
            worksheet.set_column(i, i, width, col_format)
            
    writer.close()
    output.seek(0)
    return output.read()

def display_basic_stats():
    """ÙŠØ¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    st.markdown("---")
    st.subheader("Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø© ğŸ“ˆ")
    
    report_data = fetch_all_reports() 
    
    total_count = 0
    if report_data and report_data[0]:
        records, _ = report_data
        total_count = len(records)
    
    st.metric(
        label="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª/Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", 
        value=total_count,
        help="ÙŠÙ…Ø«Ù„ Ø¹Ø¯Ø¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„ØªÙŠ ØªÙ… ØªØ£ÙƒÙŠØ¯ Ø­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."
    )
    st.markdown("---")

# ===============================
# 4. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (CSS)
# ===============================
st.markdown(
    """
    <style>
    /* Ø®Ù„ÙÙŠØ© Ø¹Ø§Ù…Ø© */
    .stApp {
        background-color: #f5f7fa;
        font-family: "Tajawal", sans-serif;
    }
    /* Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1, h2, h3 {
        color: #1a3c6e !important;
        font-weight: 700 !important;
    }
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø®Ø· */
    p, div, span {
        font-size: 16px !important;
    }
    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton button {
        background-color: #1a3c6e !important;
        color: white !important;
        border-radius: 10px !important;
        padding: 10px 25px !important;
        font-size: 17px !important;
        transition: 0.3s;
    }
    .stButton button:hover {
        background-color: #102649 !important;
        transform: scale(1.05);
    }
    /* Ø§Ù„Ø¬Ø¯ÙˆÙ„ */
    .stDataFrame table {
        border-radius: 10px !important;
    }
    .dataframe tbody tr:nth-child(odd) {
        background-color: #eef2f7 !important;
    }
    .dataframe tbody tr:hover {
        background-color: #d7e3ff !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)


# ===============================
# 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ù‡Ù†Ø§)
# ===============================
def main():
    st.set_page_config(layout="wide", page_title="Ø£Ø¯Ø§Ø© Ø§Ø³ØªØ®Ù„Ø§Øµ ÙˆØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø§Ù„ÙŠØ©")

    st.title("ğŸ“„ Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ")
    st.markdown("---")

    # ØªÙ‡ÙŠØ¦Ø© Session State 
    if 'extracted_data_df' not in st.session_state:
        st.session_state['extracted_data_df'] = pd.DataFrame()

    uploaded_files = st.file_uploader(
        "ğŸ“¤ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª)",
        type=["pdf", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )

    if uploaded_files:
        all_extracted_data = []
        
        if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"):
            
            extraction_tasks = []
            for uploaded_file in uploaded_files:
                file_bytes, file_name = uploaded_file.read(), uploaded_file.name
                file_type = file_name.split('.')[-1].lower()
                extraction_tasks.append((file_bytes, file_name, file_type))

            st.info(f"â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {len(extraction_tasks)} Ù…Ù„ÙØ§Øª Ø¨Ø§Ù„ØªÙˆØ§Ø²ÙŠ... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª.")

            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                results = [executor.submit(extract_financial_data, bytes, name, type) 
                           for bytes, name, type in extraction_tasks]
                
                progress_bar = st.progress(0)
                processed_count = 0

                for future in concurrent.futures.as_completed(results):
                    data = future.result()
                    if data:
                        all_extracted_data.append(data)
                    
                    processed_count += 1
                    progress_bar.progress(processed_count / len(extraction_tasks))
            
            if all_extracted_data:
                st.success("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª.")
                new_df = pd.DataFrame(all_extracted_data)
                
                display_cols = ["Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] + REPORT_FIELDS_ARABIC
                new_df = new_df.reindex(columns=display_cols, fill_value='ØºÙŠØ± Ù…ØªÙˆÙØ±')
                
                st.session_state['extracted_data_df'] = pd.concat(
                    [st.session_state['extracted_data_df'], new_df], 
                    ignore_index=True
                )
            else:
                st.error("âŒ ÙØ´Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡.")


    # ======================================================
    # ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ + Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
    # ======================================================
    # ğŸ’¡ ØªÙ… ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¨Ø§Ø¯Ø¦Ø© Ù„Ù‡Ø°Ù‡ Ø§Ù„ÙƒØªÙ„Ø© Ù„ØªÙƒÙˆÙ† Ø¯Ø§Ø®Ù„ Ø¯Ø§Ù„Ø© main()
    if not st.session_state['extracted_data_df'].empty:
        st.subheader("âœï¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„)")

        # ğŸ’¡ Ø²Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¯Ù„Ø§Ù„Ø©
        if st.button("ğŸ’¡ Ø§Ø³ØªØ®Ø±Ø¬ Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"):
            temp_df = st.session_state['extracted_data_df'].copy()
            
            # Ù†Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø¤Ù‚Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¥Ø°Ø§ ØªÙ… Ø§Ù„Ø¶ØºØ· Ø£ÙƒØ«Ø± Ù…Ù† Ù…Ø±Ø©
            if 'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)' in temp_df.columns:
                 temp_df.drop(columns=['Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)'], inplace=True, errors='ignore')
            
            def get_delala_description(row):
                delala_num = str(row.get('Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')).strip()
                try:
                    num = int(delala_num)
                    return f"({num}) {DELALAT_MAPPING.get(num, 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© ØºÙŠØ± ØµØ­ÙŠØ­')}"
                except ValueError:
                    return delala_num
            
            if 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' in temp_df.columns:
                temp_df.insert(
                    temp_df.columns.get_loc('Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©') + 1,
                    'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)',
                    temp_df.apply(get_delala_description, axis=1)
                )
            
            st.session_state['extracted_data_df'] = temp_df
            st.rerun()
            
        # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
        edited_df = st.data_editor(
            st.session_state['extracted_data_df'],
            use_container_width=True,
            num_rows="dynamic"
        )

        st.markdown("---")

        # Ø²Ø± Ø§Ù„Ø­ÙØ¸
        if st.button("ğŸ’¾ ØªØ£ÙƒÙŠØ¯ ÙˆØ­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            saved_count = 0
            total_rows = len(edited_df)
            status_placeholder = st.empty() 

            for index, row in edited_df.iterrows():
                row_data = dict(row)
                
                # Ø­Ø°Ù Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                if 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' in row_data:
                    del row_data['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª']
                if 'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)' in row_data:
                    del row_data['Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)']
                    
                if save_to_db(row_data):
                    saved_count += 1
                else:
                    status_placeholder.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø±Ù‚Ù… {index + 1}.")
                    break

            if saved_count == total_rows:
                status_placeholder.success(f"âœ… ØªÙ… Ø­ÙØ¸ {saved_count} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
                st.session_state['extracted_data_df'] = pd.DataFrame() 
                st.rerun() 
            elif saved_count > 0:
                status_placeholder.warning(f"âš ï¸ ØªÙ… Ø­ÙØ¸ {saved_count} ÙÙ‚Ø·. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.")
            elif saved_count == 0 and total_rows > 0:
                 status_placeholder.error("âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ù…Ø±Ø§Ø¡ Ø£Ø¹Ù„Ø§Ù‡.")


    # ----------------------------------------------------
    # Ù‚Ø³Ù… Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø© (Ø§Ù„Ù…Ø¹Ø¯Ù„)
    # ----------------------------------------------------
    display_basic_stats()
    
    # ----------------------------------------------------
    # Ù‚Ø³Ù… Ø§Ù„ØªØµØ¯ÙŠØ± Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    # ----------------------------------------------------
    st.markdown("---")
    st.subheader("ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")

    if st.button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Excel Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        report_data = fetch_all_reports()
        
        if report_data and report_data[0] is not None: 
            records, column_names = report_data
            
            with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©..."):
                excel_data_bytes = create_final_report_from_db(records, column_names)
            
            if excel_data_bytes:
                st.download_button(
                    "â¬‡ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„",
                    data=excel_data_bytes,
                    file_name="Final_Database_Report.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© ÙØ§Ø±ØºØ©.")
        else:
            st.error("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª.")


if __name__ == "__main__":
    main()
2. Ù…Ù„Ù db.py (ØªÙ… ØªØ¶Ù…ÙŠÙ† Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©)
Python

# db.py
import psycopg2
import os
from dotenv import load_dotenv
import streamlit as st
from psycopg2 import sql
import pandas as pd
import re
from itertools import permutations 
import datetime 

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‡Ø¬Ø±ÙŠ
try:
    from hijri_converter import Hijri
except ImportError:
    # Ù„Ø§ Ù†ÙˆÙ‚Ù Ø§Ù„ØªÙ†ÙÙŠØ°ØŒ ÙÙ‚Ø· Ù†ØªØ±Ùƒ ØªØ­Ø°ÙŠØ±
    Hijri = None

load_dotenv()
DB_URL = os.getenv("DATABASE_URL")

# Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (ØªÙ… Ø¥Ø¶Ø§ÙØ© "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©")
DB_COLUMN_NAMES = [
    "Ø±Ù‚Ù… Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©",
    "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©",
    "Ø§Ù„Ù…Ù‡Ù†Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ",
    "Ø±Ù‚Ù… Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
    "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰",
    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©",
    "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©", # ğŸ’¡ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù",
    "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"
]

DATA_KEYS = DB_COLUMN_NAMES

# Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ù„Ù‰ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
def arabic_to_english_numbers(text):
    if not isinstance(text, str):
        return text
    
    arabic_map = {
        'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
        'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'
    }
    return text.translate(str.maketrans(arabic_map))


def connect_db():
    """ÙŠÙ†Ø´Ø¦ Ø§ØªØµØ§Ù„Ù‹Ø§ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª."""
    try:
        if not DB_URL:
            # st.error("âŒ Ù…ØªØºÙŠØ± DATABASE_URL ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù…Ù„Ù .env")
            return None
        conn = psycopg2.connect(DB_URL, sslmode='require')
        return conn
    except Exception as e:
        st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return None

def _convert_hijri_to_date(parts_tuple):
    """
    Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©: ØªØ­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ù…ÙØªØ±Ø¶ Ø£Ù†Ù‡ Ø³Ù†Ø©ØŒ Ø´Ù‡Ø±ØŒ ÙŠÙˆÙ…) Ø¥Ù„Ù‰ ØªØ§Ø±ÙŠØ® Ù…ÙŠÙ„Ø§Ø¯ÙŠ.
    """
    if not Hijri or len(parts_tuple) != 3:
        return None
        
    try:
        y_str, m_str, d_str = [re.sub(r'[^\d]', '', p) for p in parts_tuple]
        y, m, d = int(y_str), int(m_str), int(d_str)
    except ValueError:
        return None

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© 
    if y < 1000 and y >= 400:
        y += 1000 
    elif y >= 1 and y <= 99:
        if y < 60: 
            y += 1400
        else:
            y += 1300
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø·Ø§Ù‚ Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© Ø§Ù„Ù…Ø¹Ù‚ÙˆÙ„
    if y > 1300 and y < 1500:
        if 1 <= m <= 12 and 1 <= d <= 30:
            try:
                gregorian_date = Hijri(y, m, d).to_gregorian()
                return gregorian_date 
            except Exception:
                return None
                
    return None

def clean_data_type(key, value):
    """ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ… Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚Ø§Øª ØµØ§Ù„Ø­Ø© Ù„Ù€ PostgreSQL."""
    
    # 1. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ§Ø±ØºØ©
    if value is None or value == 'ØºÙŠØ± Ù…ØªÙˆÙØ±' or value == '' or pd.isna(value):
        return None

    # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© (NUMERIC/INTEGER)
    numeric_fields = ["Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"]
    
    # ğŸ’¡ ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ù‚Ù… Ø¹Ù„Ù‰ 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©'
    if key in numeric_fields or key == "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©":
        try:
            cleaned_value = arabic_to_english_numbers(str(value))
            
            # Ù…Ù†Ø·Ù‚ Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© (ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† INTEGER)
            if key == "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©":
                # Ù†Ù†Ø¸Ù Ù…Ù† Ø£ÙŠ Ø£Ø­Ø±Ù ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ©
                num_str = re.sub(r'[^\d]', '', cleaned_value)
                if not num_str:
                    return None
                num = int(num_str)
                # Ø­ÙØ¸ Ù‚ÙŠÙ…Ø© NULL Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚ (1-11)
                return num if 1 <= num <= 11 else None 
            
            # Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ø§Ù„Ù…ØªØºÙŠØ±)
            temp_val = re.sub(r'[^\d\.,-]', '', cleaned_value)
            last_separator_index = max(temp_val.rfind('.'), temp_val.rfind(','))
            
            if last_separator_index != -1:
                integer_part = temp_val[:last_separator_index]
                decimal_part = temp_val[last_separator_index+1:]
                integer_part = re.sub(r'[,\.]', '', integer_part) 
                
                if len(decimal_part) > 2:
                    final_val = integer_part + decimal_part
                    final_val = re.sub(r'[^\d\.-]', '', final_val)
                    return float(final_val)
                else:
                    final_val = f"{integer_part}.{decimal_part}"
                    final_val = re.sub(r'[^\d\.-]', '', final_val)
                    return float(final_val)
            else:
                final_val = re.sub(r'[^\d\.-]', '', temp_val)
                if not final_val:
                    return None
                return float(final_val)

        except ValueError:
            return None
            
    # 3. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© (DATE)
    date_fields = ["ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰"]
    if key in date_fields:
        
        date_str = arabic_to_english_numbers(str(value))
        clean_str_base = re.sub(r'[^\d/\-.]', '', date_str).strip()
        
        is_hijri_expected = key in ["ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰"]

        # Ø£. Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ Ù…ÙŠÙ„Ø§Ø¯ÙŠ Ù…Ø¨Ø§Ø´Ø±
        if not is_hijri_expected:
            try:
                date_obj = pd.to_datetime(clean_str_base, errors='coerce', dayfirst=False)
                if pd.notna(date_obj) and date_obj.year > 1800:
                    return date_obj.date()
            except Exception:
                pass
        
        # Ø¨. Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‡Ø¬Ø±ÙŠ 
        if Hijri:
            try:
                parts = [p for p in re.split(r'[/\-.]', clean_str_base) if p.strip()] 
                
                if len(parts) == 3:
                    possible_orders = set(permutations(parts))

                    for p in possible_orders:
                        result = _convert_hijri_to_date(p)
                        if result:
                            return result
                            
            except Exception as e:
                #st.error(f"âŒ Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ù‡Ø¬Ø±ÙŠ Ù„Ù€ '{key}'. Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ù†Ø¸ÙØ©: '{clean_str_base}'. Ø§Ù„Ø®Ø·Ø£: {e}")
                pass 
        
        if clean_str_base and key in date_fields:
            # st.warning(f"âŒ ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù„Ù€ '{key}'. Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø®Ø§Ù…: '{value}'. Ø³ÙŠØªÙ… Ø­ÙØ¸ NULL.")
            pass
            
        return None

    # 4. Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø®Ø±Ù‰ (VARCHAR/TEXT)
    return value


def save_to_db(extracted_data):
    """ÙŠØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© Ø¥Ù„Ù‰ Ø¬Ø¯ÙˆÙ„ ØªÙ‚Ø§Ø±ÙŠØ±_Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡."""
    conn = connect_db()
    if not conn:
        return False
        
    processed_data_for_display = {}
    insert_columns = []
    insert_values = []
    
    for key in DATA_KEYS:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ extracted_data
        value = extracted_data.get(key)
        
        processed_value = clean_data_type(key, value)
        
        processed_data_for_display[key] = str(processed_value) if isinstance(processed_value, datetime.date) else processed_value

        insert_columns.append(sql.Identifier(key))
        insert_values.append(sql.Literal(processed_value))

    st.info("âœ… Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ø§Ù„ØªÙŠ Ø³ÙŠØªÙ… Ø­ÙØ¸Ù‡Ø§ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
    st.json(processed_data_for_display)

    
    try:
        cur = conn.cursor()
        
        columns_sql = sql.SQL(', ').join(insert_columns)
        values_list = sql.SQL(', ').join(insert_values)

        insert_query = sql.SQL("""
            INSERT INTO public.ØªÙ‚Ø§Ø±ÙŠØ±_Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡ ({columns})
            VALUES ({values})
        """).format(
            columns=columns_sql,
            values=values_list
        )
        
        cur.execute(insert_query)
        
        conn.commit()
        cur.close()
        conn.close()
        # st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!") # ÙŠØªÙ… Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ app.py
        return True
    except Exception as e:
        # st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}") # ÙŠØªÙ… Ø¹Ø±Ø¶Ù‡Ø§ ÙÙŠ app.py
        if 'does not exist' in str(e):
             st.error("ğŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ Ø¸Ù‡Ø± Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£ØŒ ÙØªØ£ÙƒØ¯ Ø£Ù†Ùƒ Ø£Ù†Ø´Ø£Øª Ø¹Ù…ÙˆØ¯ 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' ÙÙŠ Ø¬Ø¯ÙˆÙ„ PostgreSQL Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ Ø¨Ù†ÙˆØ¹ **INTEGER**.")
        
        if conn:
            conn.rollback()
            conn.close()
        return False

def fetch_all_reports():
    """ÙŠØ¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù…Ù† Ø¬Ø¯ÙˆÙ„ ØªÙ‚Ø§Ø±ÙŠØ±_Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡."""
    conn = connect_db()
    if not conn:
        return None, None

    try:
        cur = conn.cursor()
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© Ù„ÙƒÙŠ ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ DataFrame ÙÙŠ app.py
        select_columns = sql.SQL(', ').join([sql.Identifier(col) for col in DB_COLUMN_NAMES])

        select_query = sql.SQL('SELECT id, {columns} FROM public.ØªÙ‚Ø§Ø±ÙŠØ±_Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡').format(columns=select_columns)
        
        cur.execute(select_query)
        
        # ÙŠØ¬Ø¨ Ø¯Ù…Ø¬ Ø¹Ù…ÙˆØ¯ id Ù…Ø¹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£Ø®Ø±Ù‰
        column_names = ['id'] + [desc[0] for desc in cur.description[1:]] 
        records = cur.fetchall()
        
        cur.close()
        conn.close()
        
        return records, column_names

    except Exception as e:
        st.error(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        if conn:
            conn.close()
        return None, None
