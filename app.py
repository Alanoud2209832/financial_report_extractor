# -*- coding: utf-8 -*-
# app.py
import streamlit as st
import pandas as pd
import json
import io
import base64
import os
import re 
import pytz 
from google import genai
from google.genai.errors import APIError
import time # ØªÙ… Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ø§ Ù„Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø®Ø§ØµÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
from db import save_to_db, fetch_all_reports

# ===============================
# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API
# ===============================
# ÙŠÙØ¶Ù„ ØªØ­Ù…ÙŠÙ„ Ù‡Ø°Ø§ Ù…Ù† Ù…Ù„Ù .env ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬
# **ØªÙ†Ø¨ÙŠÙ‡**: ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… os.getenv("GEMINI_API_KEY") ÙˆØªØ¬Ù†Ø¨ ÙˆØ¶Ø¹ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ø¨Ø§Ø´Ø±Ø©
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "AIzaSyAnvwxAKUKdzPkHUqPylCYmlWvo4uzFdpQ") 
MODEL_NAME = 'gemini-2.5-flash-preview-09-2025'
SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ÙŠØ§Ù†Ø§Øª Ø¢Ù„ÙŠ (OCR/NLP). Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ© "
    "ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† JSON ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø¨Ø¯Ù‚Ø©. ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ **Ù†Ø³Ø®** Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© "
    "ØªÙ…Ø§Ù…Ø§ ÙƒÙ…Ø§ ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠØŒ Ø¯ÙˆÙ† ØªÙ„Ø®ÙŠØµ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØµÙŠØ§ØºØ©ØŒ Ø®Ø§ØµØ©Ù‹ ÙÙŠ Ø­Ù‚Ù„ 'Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡'. "
    "Ù‚Ù… Ø¨ØªØµØ­ÙŠØ­ Ø£ÙŠ Ø§Ù†Ø¹ÙƒØ§Ø³ Ø£Ùˆ ØªØ´ÙˆÙŠØ´ ÙÙŠ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© 'ØºÙŠØ± Ù…ØªÙˆÙØ±' Ù„Ù„Ø­Ù‚ÙˆÙ„ ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©."
)

REPORT_FIELDS_ARABIC = [
    "Ø±Ù‚Ù… Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©",
    "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©",
    "Ø§Ù„Ù…Ù‡Ù†Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ",
    "Ø±Ù‚Ù… Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
    "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰",
    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"
]

RESPONSE_SCHEMA = {
    "type": "OBJECT",
    "properties": {
        field: {"type": "STRING", "description": f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© Ù„Ù€: {field}"}
        for field in REPORT_FIELDS_ARABIC
    },
    "propertyOrdering": REPORT_FIELDS_ARABIC
}

# ğŸ’¡ Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¥Ù„Ù‰ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
def arabic_to_english_numbers(text):
    if not isinstance(text, str):
        return text
    arabic_map = {'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
                  'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'}
    return text.translate(str.maketrans(arabic_map))

# ğŸ’¡ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ´ØªØª (Ø§Ù„Ù…Ø¤Ø´Ø±)
def check_for_suspicion(data):
    """ÙŠØ¶ÙŠÙ Ø¹Ù„Ø§Ù…Ø© 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' (ğŸ”´) Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§."""
    suspicion_indicator = ""
    
    # --- 1. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© (Ø§Ù„Ù…Ø«Ø§Ù„: 0945/06/20) ---
    date_fields = ["ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯"]
    for field in date_fields:
        date_val = data.get(field, "")
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
            date_str_en = arabic_to_english_numbers(str(date_val))
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù†Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙÙˆØ§ØµÙ„ Ù…ØªØ¹Ø¯Ø¯Ø©
            parts = re.split(r'[/\-.]', date_str_en)
            if len(parts) == 3:
                # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø£Ø­Ø±Ù ØºÙŠØ± Ø±Ù‚Ù…ÙŠØ© Ù…Ù† Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„ (Ø§Ù„Ø³Ù†Ø©)
                year_str = re.sub(r'[^\d]', '', parts[0])
                year = int(year_str) if year_str else 0
                
                # Ø§Ù„Ù…Ø¹ÙŠØ§Ø±: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø³Ù†Ø© Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø© Ø£Ùˆ Ø®Ø§Ø±Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚ 1400-1500
                # Ù‡Ø°Ø§ Ø§Ù„Ø´Ø±Ø· ÙŠÙ„ØªÙ‚Ø· Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù…Ø«Ù„ Ù‚Ø±Ø§Ø¡Ø© 0945 ÙƒÙ€ 945
                if year > 100 and year < 1400: 
                    suspicion_indicator += f"ğŸ”´ ({field}: Ø³Ù†Ø© ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ©) "
        except Exception:
            # Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (Ù…Ø«Ù„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù†ØµÙŠØ©)
            if str(date_val).strip() not in ['ØºÙŠØ± Ù…ØªÙˆÙØ±', '']:
                 suspicion_indicator += f"ğŸ”´ ({field}: ØµÙŠØºØ© ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø©) "
            pass

    # --- 2. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© ÙƒØµÙØ± ---
    financial_fields = ["Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"]
    for field in financial_fields:
        val = data.get(field, "")
        if str(val).strip() in ['0', '0.00', 'Ù ', 'Ù ,Ù Ù ']:
             suspicion_indicator += f"âš ï¸ ({field} = 0) "

    return suspicion_indicator.strip() or "âœ… Ø³Ù„ÙŠÙ…"

# ===============================
# 2. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©)
# ===============================
def extract_financial_data(file_bytes, file_name, file_type):
    MAX_RETRIES = 3 # ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
    for attempt in range(MAX_RETRIES):
        try:
            client = genai.Client(api_key=GEMINI_API_KEY)
            mime_type = "application/pdf" if file_type=='pdf' else f"image/{'jpeg' if file_type=='jpg' else file_type}"

            content_parts = [
                "Ù‚Ù… Ø¨Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...",
                {"inlineData": {"data": base64.b64encode(file_bytes).decode('utf-8'), "mimeType": mime_type}}
            ]

            config = {
                "systemInstruction": SYSTEM_PROMPT,
                "responseMimeType": "application/json",
                "responseSchema": RESPONSE_SCHEMA
            }

            with st.spinner(f"â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…Ù† '{file_name}' - Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1} / {MAX_RETRIES}..."):
                response = client.models.generate_content(model=MODEL_NAME, contents=content_parts, config=config)

            extracted_data = json.loads(response.text)
            extracted_data['Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù'] = file_name
            
            # ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© "Asia/Riyadh" (ØªÙˆÙ‚ÙŠØª Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©)
            riyadh_tz = pytz.timezone('Asia/Riyadh')
            extracted_data['ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ'] = pd.Timestamp.now(tz=riyadh_tz).strftime("%Y-%m-%d %H:%M:%S")

            # Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª
            extracted_data['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª'] = check_for_suspicion(extracted_data) 
            
            st.success(f"âœ… ØªÙ… Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…Ù† '{file_name}' Ø¨Ù†Ø¬Ø§Ø­!")
            return extracted_data 

        except APIError as e:
            # ğŸ’¡ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø®Ø·Ø£ 503 (Service Unavailable)
            if '503 UNAVAILABLE' in str(e) and attempt < MAX_RETRIES - 1:
                wait_time = 2 ** attempt  # ØªØ£Ø®ÙŠØ± Ù…Ø¶Ø§Ø¹Ù: 1ØŒ 2ØŒ 4 Ø«ÙˆØ§Ù†Ù
                st.warning(f"âš ï¸ Ø®Ø·Ø£ Ù…Ø¤Ù‚Øª 503. Ø³ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ {wait_time} Ø«ÙˆØ§Ù†Ù.")
                time.sleep(wait_time)
                continue  # Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªØ§Ù„ÙŠØ©
            else:
                st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨Ø¹Ø¯ {attempt + 1} Ù…Ø­Ø§ÙˆÙ„Ø§Øª: {e}")
                return None 
        
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ: {e}")
            return None
    
    # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª
    return None

def create_final_report_from_db(records, column_names):
    import xlsxwriter
    if not records: 
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§.")
        return None

    df = pd.DataFrame(records, columns=column_names)
    df.insert(0, '#', range(1, len(df) + 1))
    
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    
    # ØªØµØ­ÙŠØ­ Ø§Ù„Ø®Ø·Ø£: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… ÙˆØ±Ù‚Ø© Ø¹Ù…Ù„ Ù„Ø§ ÙŠØªØ¬Ø§ÙˆØ² 31 Ø­Ø±ÙØ§Ù‹
    sheet_name = 'Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ' 
    
    df.to_excel(writer, sheet_name=sheet_name, index=False)
    
    # ØªÙ†Ø³ÙŠÙ‚ Excel
    workbook, worksheet = writer.book, writer.sheets[sheet_name]
    worksheet.right_to_left()
    col_format = workbook.add_format({'text_wrap': True, 'align': 'right', 'valign': 'top'})
    
    for i, col_name in enumerate(df.columns):
        if col_name == 'Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡':
            worksheet.set_column(i, i, 120, col_format)
        else:
            width = 25 if col_name in ["Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] else 18
            worksheet.set_column(i, i, width, col_format)
            
    writer.close()
    output.seek(0)
    return output.read()

import streamlit as st
import pandas as pd

# ===============================
# 1. ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (CSS)
# ===============================
st.markdown(
    """
    <style>
    /* Ø®Ù„ÙÙŠØ© Ø¹Ø§Ù…Ø© */
    .stApp {
        background-color: #f5f7fa;
        font-family: "Tajawal", sans-serif;
    }

    /* Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† */
    h1, h2, h3 {
        color: #1a3c6e !important;
        font-weight: 700 !important;
    }

    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø®Ø· */
    p, div, span {
        font-size: 16px !important;
    }

    /* Ø§Ù„Ø£Ø²Ø±Ø§Ø± */
    .stButton button {
        background-color: #1a3c6e !important;
        color: white !important;
        border-radius: 10px !important;
        padding: 10px 25px !important;
        font-size: 17px !important;
        transition: 0.3s;
    }
    .stButton button:hover {
        background-color: #102649 !important;
        transform: scale(1.05);
    }

    /* Ø§Ù„Ø¬Ø¯ÙˆÙ„ */
    .stDataFrame table {
        border-radius: 10px !important;
    }
    .dataframe tbody tr:nth-child(odd) {
        background-color: #eef2f7 !important;
    }
    .dataframe tbody tr:hover {
        background-color: #d7e3ff !important;
    }

    </style>
    """,
    unsafe_allow_html=True
)


# ===============================
# 2. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ===============================
def main():

    st.set_page_config(layout="wide", page_title="Ø£Ø¯Ø§Ø© Ø§Ø³ØªØ®Ù„Ø§Øµ ÙˆØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø§Ù„ÙŠØ©")

    st.title("Ù†Ø¸Ø§Ù… Ø°ÙƒÙŠ Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ")
    st.markdown("---")

    uploaded_files = st.file_uploader(
        "ğŸ“¤ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª (ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª)",
        type=["pdf", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )

    # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if uploaded_files:
        all_extracted_data = []

        if 'extracted_data_df' not in st.session_state:
            st.session_state['extracted_data_df'] = pd.DataFrame()

        if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"):
            for uploaded_file in uploaded_files:
                file_bytes, file_name = uploaded_file.read(), uploaded_file.name
                file_type = file_name.split('.')[-1].lower()
                st.info(f"â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: **{file_name}**")

                data = extract_financial_data(file_bytes, file_name, file_type)

                if data:
                    all_extracted_data.append(data)

            if all_extracted_data:
                new_df = pd.DataFrame(all_extracted_data)

                # Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆØ¶Ø©
                display_cols = ["Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] + REPORT_FIELDS_ARABIC
                new_df = new_df.reindex(columns=display_cols, fill_value='ØºÙŠØ± Ù…ØªÙˆÙØ±')

                st.session_state['extracted_data_df'] = pd.concat(
                    [st.session_state['extracted_data_df'], new_df],
                    ignore_index=True
                )

    # ======================================================
    # ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ + Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
    # ======================================================
    if not st.session_state['extracted_data_df'].empty:
        st.subheader("âœï¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„)")

        edited_df = st.data_editor(
            st.session_state['extracted_data_df'],
            use_container_width=True,
            num_rows="dynamic"
        )

        st.markdown("---")

        # ----------------------------
# Ù‚Ø³Ù…: ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ ÙˆØ³Ù‡Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ----------------------------
import matplotlib.pyplot as plt
from io import BytesIO

def safe_to_numeric(series):
    """Ø­ÙˆÙ‘Ù„ Ù‚ÙŠÙ… (Ù‚Ø¯ ØªÙƒÙˆÙ† Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©) Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… float Ø¨Ø£Ù…Ø§Ù†."""
    def conv(v):
        if pd.isna(v): 
            return None
        s = str(v).strip()
        s = arabic_to_english_numbers(s)
        # Ø¥Ø²Ø§Ù„Ø© ÙÙˆØ§ØµÙ„ Ø¢Ù„Ø§Ù Ø´Ø§Ø¦Ø¹Ø© (ØŒ ,) ÙˆØ§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ÙØ§ØµÙ„Ø© Ø§Ù„Ø¹Ø´Ø±ÙŠØ© Ø¥Ù† ÙˆØ¬Ø¯Øª
        s = s.replace(',', '').replace('ØŒ', '')
        s = s.replace('Ù«', '.').replace(' ', '')
        # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ Ø±Ù…ÙˆØ² Ø¹Ù…Ù„Ø©
        s = re.sub(r'[^\d.\-]', '', s)
        try:
            return float(s) if s != '' else None
        except:
            return None
    return series.apply(conv)

if 'extracted_data_df' in st.session_state and not st.session_state['extracted_data_df'].empty:
    df_for_analysis = st.session_state['extracted_data_df'].copy()

    st.markdown("---")
    st.subheader("ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø³Ø±ÙŠØ¹ ÙˆÙ…Ø¨Ø³Ø· Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    # ------- Ù…Ø¤Ø´Ø±Ø§Øª Ø³Ø±ÙŠØ¹Ø© (KPI) -------
    total_records = len(df_for_analysis)
    total_files = df_for_analysis['Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù'].nunique() if 'Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù' in df_for_analysis.columns else 'ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ'
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡ Ù…Ù† Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯
    if 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' in df_for_analysis.columns:
        suspicious_mask = df_for_analysis['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª'].astype(str).str.contains('ğŸ”´|âš ï¸')
        suspicious_count = suspicious_mask.sum()
    else:
        suspicious_count = 0

    k1, k2, k3 = st.columns(3)
    k1.metric("Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª", total_records)
    k2.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª", total_files)
    k3.metric("Ø³Ø¬Ù„Ø§Øª Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§", suspicious_count)

    st.markdown("")

    # ------- Ø±Ø³Ù…: Ø­Ø§Ù„Ø© Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª (Ø¯Ø§Ø¦Ø±ÙŠ) -------
    if 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' in df_for_analysis.columns:
        status_counts = df_for_analysis['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª'].fillna('ØºÙŠØ± Ù…ØªÙˆÙØ±').value_counts()
        fig1, ax1 = plt.subplots(figsize=(4,4))
        ax1.pie(status_counts.values, labels=status_counts.index, autopct='%1.1f%%', startangle=90, wedgeprops={'edgecolor': 'white'})
        ax1.axis('equal')
        st.pyplot(fig1)
        plt.close(fig1)

    # ------- Ø±Ø³Ù…: Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª (Ø´Ø±ÙŠØ·ÙŠ) -------
    if 'Ø§Ù„Ø¬Ù†Ø³ÙŠØ©' in df_for_analysis.columns:
        top_nationalities = df_for_analysis['Ø§Ù„Ø¬Ù†Ø³ÙŠØ©'].fillna('ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ').value_counts().nlargest(8)
        fig2, ax2 = plt.subplots(figsize=(7,4))
        top_nationalities.plot(kind='bar', ax=ax2)
        ax2.set_title("Ø£ÙƒØ«Ø± Ø§Ù„Ø¬Ù†Ø³ÙŠØ§Øª Ø¸Ù‡ÙˆØ±Ø§Ù‹")
        ax2.set_xlabel("")
        ax2.set_ylabel("Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª")
        plt.tight_layout()
        st.pyplot(fig2)
        plt.close(fig2)

    # ------- Ø±Ø³Ù…: ØªÙˆØ²ÙŠØ¹ Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨ (Ù‡ÙŠØ³ØªÙˆØºØ±Ø§Ù…) -------
    if 'Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨' in df_for_analysis.columns:
        numeric_balance = safe_to_numeric(df_for_analysis['Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨'])
        if numeric_balance.dropna().empty:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚ÙŠÙ… Ø±Ù‚Ù…ÙŠØ© Ù„Ø¹Ù…ÙˆØ¯ 'Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨' Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù….")
        else:
            fig3, ax3 = plt.subplots(figsize=(7,4))
            ax3.hist(numeric_balance.dropna(), bins=20)
            ax3.set_title("ØªÙˆØ²ÙŠØ¹ Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨")
            ax3.set_xlabel("Ø§Ù„Ø±ØµÙŠØ¯")
            ax3.set_ylabel("ØªØ±Ø¯Ø¯")
            plt.tight_layout()
            st.pyplot(fig3)
            plt.close(fig3)

    # ------- Ø¬Ø¯ÙˆÙ„: Ø£Ø¹Ù„Ù‰ 10 Ø³Ø¬Ù„Ø§Øª Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§ -------
    if 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' in df_for_analysis.columns:
        suspicious_df = df_for_analysis[suspicious_mask].copy()
        if not suspicious_df.empty:
            st.markdown("**âš ï¸ Ù…Ù„Ø®Øµ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§ (Ø£Ø¹Ù„Ù‰ 10):**")
            st.dataframe(suspicious_df.head(10))
        else:
            st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§ Ù„Ø¹Ø±Ø¶Ù‡Ø§.")

    # ------- Ø²Ø± Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙƒÙ…Ù„Ù CSV -------
    summary = {
        "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø³Ø¬Ù„Ø§Øª": [total_records],
        "Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª": [total_files],
        "Ø³Ø¬Ù„Ø§Øª Ù…Ø´ÙƒÙˆÙƒ ÙÙŠÙ‡Ø§": [suspicious_count]
    }
    summary_df = pd.DataFrame(summary)

    csv_buffer = BytesIO()
    combined_for_export = {
        "summary": summary_df,
        "top_nationalities": df_for_analysis['Ø§Ù„Ø¬Ù†Ø³ÙŠØ©'].value_counts().head(20) if 'Ø§Ù„Ø¬Ù†Ø³ÙŠØ©' in df_for_analysis.columns else pd.Series(dtype=int),
        "suspicious_samples": suspicious_df.head(50) if 'Ø§Ù„Ø¬Ù†Ø³ÙŠØ©' in df_for_analysis.columns else pd.DataFrame()
    }
    # Ù„ØªØµØ¯ÙŠØ±: Ø³Ù†ØµØ¯Ø± ÙÙ‚Ø· summary Ùˆ top_nationalities Ùˆ Ø£ÙˆÙ„ 50 Ù…Ø´ÙƒÙˆÙƒ
    # Ù†ÙØµØ¯Ø± ÙƒÙ€ CSV ÙˆØ§Ø­Ø¯ (summary + top nationalities + suspects)
    export_df = pd.DataFrame()
    # Ø¥Ø¶Ø§ÙØ© summary
    export_df = pd.concat([export_df, summary_df], axis=1)
    # Ø¥Ø¶Ø§ÙØ© top_nationalities ÙÙŠ Ø£Ø¹Ù…Ø¯Ø© Ø¥Ø¶Ø§ÙÙŠØ© (Ø¥Ù† ÙˆÙØ¬ÙØ¯)
    if 'Ø§Ù„Ø¬Ù†Ø³ÙŠØ©' in df_for_analysis.columns:
        tn = df_for_analysis['Ø§Ù„Ø¬Ù†Ø³ÙŠØ©'].value_counts().reset_index()
        tn.columns = ['Ø§Ù„Ø¬Ù†Ø³ÙŠØ©', 'Ø§Ù„Ø¹Ø¯Ø¯']
        # Ù†Ø­Ø±Øµ Ø¹Ù„Ù‰ ØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ CSV Ù…Ù†ÙØµÙ„ Ø¨Ø§Ù„Ø£Ø³ÙÙ„
        combined_csv = export_df.to_csv(index=False, encoding='utf-8-sig')
        tn_csv = tn.to_csv(index=False, encoding='utf-8-sig')
        suspects_csv = suspicious_df.head(200).to_csv(index=False, encoding='utf-8-sig')
        full_csv = "### summary\n" + combined_csv + "\n\n### top_nationalities\n" + tn_csv + "\n\n### suspicious_samples\n" + suspects_csv
        st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (CSV)", data=full_csv, file_name="analysis_summary.csv", mime="text/csv")
    else:
        st.download_button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ (CSV)", data=export_df.to_csv(index=False, encoding='utf-8-sig'), file_name="analysis_summary.csv", mime="text/csv")


    
        # Ø²Ø± Ø§Ù„Ø­ÙØ¸
        if st.button("ğŸ’¾ ØªØ£ÙƒÙŠØ¯ ÙˆØ­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            saved_count = 0
            total_rows = len(edited_df)
            status_placeholder = st.empty()

            for index, row in edited_df.iterrows():
                row_data = dict(row)

                # Ø­Ø°Ù Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ´ØªØª
                if 'Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª' in row_data:
                    del row_data['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª']

                if save_to_db(row_data):
                    saved_count += 1
                else:
                    status_placeholder.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø±Ù‚Ù… {index + 1}.")
                    break

            if saved_count == total_rows:
                status_placeholder.success(f"âœ… ØªÙ… Ø­ÙØ¸ {saved_count} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
                st.session_state['extracted_data_df'] = pd.DataFrame()
                st.rerun()
            else:
                status_placeholder.warning(f"âš ï¸ ØªÙ… Ø­ÙØ¸ {saved_count} ÙÙ‚Ø·. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.")


    # ======================================================
    # ğŸ“Š Ù‚Ø³Ù… Ø§Ù„ØªØµØ¯ÙŠØ±
    # ======================================================
    st.markdown("---")
    st.subheader("ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")

    if st.button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Excel"):
        report_data = fetch_all_reports()

        if report_data and report_data[0] is not None:
            records, column_names = report_data

            with st.spinner("ğŸ“ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel..."):
                excel_data_bytes = create_final_report_from_db(records, column_names)

            if excel_data_bytes:
                st.download_button(
                    "â¬‡ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„",
                    data=excel_data_bytes,
                    file_name="Final_Database_Report.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
        else:
            st.error("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")


# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if __name__ == "__main__":
    main()
