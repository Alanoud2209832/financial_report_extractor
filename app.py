# app.py
import streamlit as st
import pandas as pd
import json
import io
import base64
import os
import re
import pytz
import time
from dotenv import load_dotenv
from openai import OpenAI
from sqlite3 import OperationalError
from db import save_to_db, fetch_all_reports, initialize_db

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù…Ù† Ù…Ù„Ù .env Ø¥Ù† ÙˆÙØ¬Ø¯
load_dotenv()

# ===============================
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª OpenAI
# ===============================
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
if not OPENAI_API_KEY:
    st.error("âŒ Ù…ÙØªØ§Ø­ OPENAI_API_KEY ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø£Ø¶ÙÙ‡ ÙÙŠ Ù…Ù„Ù .env (Ø§Ù†Ø¸Ø± .env.example).")

# Ù†Ù…ÙˆØ°Ø¬ ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø© (Ø¬Ø±Ø¨ gpt-4o-mini Ø£Ùˆ gpt-4.1)
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  

client = OpenAI(api_key=OPENAI_API_KEY)

# ===============================
# Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± (Ø«Ø§Ø¨Øª)
# ===============================
REPORT_FIELDS_ARABIC = [
    "Ø±Ù‚Ù… Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… Ø§Ù„Ù‡ÙˆÙŠØ©",
    "Ø§Ù„Ø¬Ù†Ø³ÙŠØ©", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…ÙŠÙ„Ø§Ø¯ Ø§Ù„ÙˆØ§ÙØ¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø®ÙˆÙ„", "Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©",
    "Ø§Ù„Ù…Ù‡Ù†Ø©", "Ø±Ù‚Ù… Ø§Ù„Ø¬ÙˆØ§Ù„", "Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©", "Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ",
    "Ø±Ù‚Ù… Ø§Ù„ÙˆØ§Ø±Ø¯", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ",
    "Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†", "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰",
    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©",
    "Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©"
]

RESPONSE_SCHEMA = {
    "type": "object",
    "properties": {
        field: {"type": "string", "description": f"Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© Ù„Ù€: {field}"}
        for field in REPORT_FIELDS_ARABIC
    }
}

DELALAT_MAPPING = {
    1: "ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹Ø§ØªØŒ Ø­ÙˆØ§Ù„Ø§Øª Ø³Ø­ÙˆØ¨Ø§Øª Ù…Ø´ØªØ±ÙŠØ§Øª) ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚ÙŠÙ… Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ Ø§Ù„Ø³Ù†ÙˆÙŠ.",
    2: "ØªØ­ÙˆÙŠÙ„Ø§Øª Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø­Ø³Ø§Ø¨ Ø¹Ù…ÙŠÙ„ Ù…Ù‚ÙŠÙ… Ø§Ù„Ù‰ Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ.",
    3: "Ø­ÙˆØ§Ù„Ø§Øª ØµØ§Ø¯Ø±Ø© Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© Ù…ØªÙ†ÙˆØ¹Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ Ù…Ù‚ÙŠÙ… Ø£Ø¬Ù†Ø¨ÙŠ Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø¯Ø§Ø¯ Ù…ØµØ±ÙˆÙØ§Øª ØªÙ†Ù… Ø¹Ù† Ø§Ù„Ù…ØªØ§Ø¬Ø±Ø© ÙÙŠÙ‡Ø§ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© Ø¨ÙŠØ¹Ù‡Ø§.",
    4: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ØµØ§Ø¯Ø±Ø© Ù…Ù† Ø­Ø³Ø§Ø¨ ÙØ±Ø¯ Ø³Ø¹ÙˆØ¯ÙŠ Ø£Ùˆ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¥Ù„Ù‰ Ø­Ø³Ø§Ø¨Ø§Øª Ø£Ø´Ø®Ø§Øµ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ù„Ø§ ØªØ±Ø¨Ø·Ù‡Ù… Ø¨Ù‡ ØºØ±Ø¶ Ø£Ùˆ Ø¹Ù„Ø§Ù‚Ø© Ø¹Ù…Ù„.",
    5: "Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª ØªØ­ÙˆÙŠÙ„ Ù…Ø§Ù„ÙŠØ© Ø®Ø§Ø±Ø¬ Ø§Ù„Ù…Ù…Ù„ÙƒØ© Ù„Ù‡ Ø£Ùˆ Ù„Ø£Ø´Ø®Ø§Øµ Ø¢Ø®Ø±ÙŠÙ† Ø¨Ù…Ø¨Ø§Ù„Øº Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ø¯Ø®Ù„Ù‡ ÙˆÙ‚Ø¯ ÙŠÙƒÙˆÙ† Ù…ØµØ¯Ø±Ù‡Ø§ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© Ù…Ù† Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ†.",
    6: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ù„Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø´Ø®ØµÙŠ Ù„Ù„Ù…Ù‚ÙŠÙ… Ø£Ùˆ Ù„Ù„Ø¨Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ø§Ø¦ØªÙ…Ø§Ù†ÙŠØ© Ø¨Ù…Ø¨Ø§Ù„Øº Ø¹Ø§Ù„ÙŠØ© ØªÙ†Ù… Ø¹Ù† Ø¥Ø¯Ø§Ø±Ø© Ù†Ø´Ø§Ø· ØªØ¬Ø§Ø±ÙŠ Ø¯Ø§Ø®Ù„ Ø§Ù„Ù…Ù…Ù„ÙƒØ©.",
    7: "Ø´Ø®Øµ Ù…Ù‚ÙŠÙ… ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø§Ù„ÙŠØ© (Ø¥ÙŠØ¯Ø§Ø¹ Ø´ÙŠÙƒ Ø£Ùˆ ØµØ±Ù Ø´ÙŠÙƒ Ø£Ùˆ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø­ÙˆØ§Ù„Ù‡ Ù…Ø§Ù„ÙŠØ©) ÙˆÙ„ÙŠØ³ Ù„Ø¯ÙŠÙ‡ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ (Ø¹Ù…ÙŠÙ„ Ø¹Ø§Ø¨Ø±).",
    8: "Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù†Ù‚Ø¯ÙŠØ© ÙÙŠ Ø­Ø³Ø§Ø¨ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ø¨Ø´ÙƒÙ„ Ù…ØªÙƒØ±Ø± Ø£Ùˆ Ø¥ÙŠØ¯Ø§Ø¹Ø§Øª Ù…Ø¨ÙŠØ¹Ø§Øª Ù†Ù‚Ø§Ø· Ø¨ÙŠØ¹ØŒ ÙŠÙ„ÙŠÙ‡Ø§ ØªÙ†ÙÙŠØ° Ø­ÙˆØ§Ù„Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© Ø£Ùˆ Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ø¹Ø¯Ø© Ø¹Ù…Ù„Ø§Ø¡ Ù…Ù‚ÙŠÙ…ÙŠÙ† Ø£Ùˆ Ø¹Ù…Ù„ÙŠØ§Øª Ø³Ø­Ø¨.",
    9: "Ø­ÙˆØ§Ù„Ø§Øª Ø¯ÙˆÙ„ÙŠØ© ÙˆØ§Ø±Ø¯Ø© Ø£Ùˆ ØµØ§Ø¯Ø±Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ Ù„Ø§ ØªØªÙ†Ø§Ø³Ø¨ Ù…Ø¹ Ù†Ø´Ø§Ø· Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„ØªØ¬Ø§Ø±ÙŠ.",
    10: "ØªÙÙˆÙŠØ¶ Ø£Ø¬Ù†Ø¨ÙŠ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø¨Ù†ÙƒÙŠ Ø¹Ø§Ø¦Ø¯ Ù„ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ ÙˆØªÙ…ÙƒÙŠÙ†Ù‡ Ù…Ù† Ø§Ù„Ø­Ø³Ø§Ø¨ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„ Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ù…Ø¨Ø±Ø± Ø£Ùˆ ØºØ±Ø¶ ÙˆØ§Ø¶Ø­.",
    11: "ÙØªØ­ Ø¹Ø¯Ø© Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„ÙØ±ÙˆØ¹ ÙƒÙŠØ§Ù† ØªØ¬Ø§Ø±ÙŠ Ù„Ù†ÙØ³ Ø§Ù„Ù†Ø´Ø§Ø· Ø¯ÙˆÙ† ÙˆØ¬ÙˆØ¯ Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ø¶Ø­ Ø¨ÙŠÙ† Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§ØªØŒ Ù†Ø¸Ø±Ø§Ù‹ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø®Ø§Øµ Ø¨Ø§Ù„ÙØ±Ø¹ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ù‚ÙŠÙ…."
}

SYSTEM_PROMPT = (
    "Ø£Ù†Øª Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¨ÙŠØ§Ù†Ø§Øª Ø¢Ù„ÙŠ (OCR/NLP). Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†Øµ ÙˆØ§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù…Ø§Ù„ÙŠØ© "
    "ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ÙƒØ§Ø¦Ù† JSON ÙˆÙÙ‚Ø§Ù‹ Ù„Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø­Ø¯Ø¯ Ø¨Ø¯Ù‚Ø©. "
    "ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø§Ù„Ù‡Ø¬Ø±ÙŠØ© ÙˆØ§Ù„Ù…ÙŠÙ„Ø§Ø¯ÙŠØ© ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ ØµÙŠØºØ© Ø±Ù‚Ù…ÙŠØ© Ù…ÙˆØ­Ø¯Ø© 'YYYY/MM/DD'. "
    "Ù‚Ù… Ø¨Ù†Ø³Ø® Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø£Ø®Ø±Ù‰ ØªÙ…Ø§Ù…Ù‹Ø§ ÙƒÙ…Ø§ ØªØ¸Ù‡Ø± ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠØŒ ÙˆØ§Ø³ØªØ®Ø¯Ù… 'ØºÙŠØ± Ù…ØªÙˆÙØ±' Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©. "
    "Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§ØµØŒ Ø¶Ø¹ ÙÙŠ Ø­Ù‚Ù„ 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' Ø±Ù‚Ù…Ù‹Ø§ ÙˆØ§Ø­Ø¯Ù‹Ø§ Ù…Ù† 1 Ø¥Ù„Ù‰ 11 Ø£Ùˆ 'ØºÙŠØ± Ù…ØªÙˆÙØ±'."
)

# ===============================
# Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø©
# ===============================
def arabic_to_english_numbers(text):
    if not isinstance(text, str):
        return text
    arabic_map = {'Ù ': '0', 'Ù¡': '1', 'Ù¢': '2', 'Ù£': '3', 'Ù¤': '4',
                  'Ù¥': '5', 'Ù¦': '6', 'Ù§': '7', 'Ù¨': '8', 'Ù©': '9'}
    return text.translate(str.maketrans(arabic_map))


def pre_process_data_fix_dates(data):
    """ØªÙØµÙ„ ØªÙˆØ§Ø±ÙŠØ® Ù…Ù„ØªØµÙ‚Ø© ÙÙŠ Ø­Ù‚Ù„ 'ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†' Ø¥Ù† ÙˆÙØ¬Ø¯Øª"""
    start_key = "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø§Ø±Ø³Ø© Ù…Ù†"
    end_key = "ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ù‰"
    start_date_value = data.get(start_key, "")
    
    if start_date_value and isinstance(start_date_value, str):
        clean_value = re.sub(r'[^\d]', '', start_date_value).strip()
        if len(clean_value) == 16:
            date1 = clean_value[:8]
            date2 = clean_value[8:]
            data[start_key] = f"{date1[:4]}/{date1[4:6]}/{date1[6:]}"
            if not data.get(end_key) or data.get(end_key).strip() in ['', 'ØºÙŠØ± Ù…ØªÙˆÙØ±']:
                data[end_key] = f"{date2[:4]}/{date2[4:6]}/{date2[6:]}"
    return data


def check_for_suspicion(data):
    suspicion_indicator = ""
    date_fields = ["ØªØ§Ø±ÙŠØ® Ø§Ù„ØµØ§Ø¯Ø±", "ØªØ§Ø±ÙŠØ® Ø§Ù„ÙˆØ§Ø±Ø¯"]
    for field in date_fields:
        date_val = data.get(field, "")
        try:
            date_str_en = arabic_to_english_numbers(str(date_val))
            parts = re.split(r'[/\-.]', date_str_en)
            if len(parts) == 3:
                year_str = re.sub(r'[^\d]', '', parts[0])
                year = int(year_str) if year_str else 0
                if year > 100 and year < 1400:
                    suspicion_indicator += f"ğŸ”´ ({field}: Ø³Ù†Ø© ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠØ©) "
        except Exception:
            if str(date_val).strip() not in ['ØºÙŠØ± Ù…ØªÙˆÙØ±', '']:
                suspicion_indicator += f"ğŸ”´ ({field}: ØµÙŠØºØ© ØºÙŠØ± Ù…ÙÙ‡ÙˆÙ…Ø©) "
            pass
    
    financial_fields = ["Ø±ØµÙŠØ¯ Ø§Ù„Ø­Ø³Ø§Ø¨", "Ø§Ù„Ø¯Ø®Ù„ Ø§Ù„Ø³Ù†ÙˆÙŠ", "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¥ÙŠØ¯Ø§Ø¹ Ø§Ù„Ø¯Ø±Ø§Ø³Ø©"]
    for field in financial_fields:
        val = data.get(field, "")
        if str(val).strip() in ['0', '0.00', 'Ù ', 'Ù ,Ù Ù ']:
            suspicion_indicator += f"âš ï¸ ({field} = 0) "
    return suspicion_indicator.strip() or "âœ… Ø³Ù„ÙŠÙ…"


# ===============================
# Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¹Ø¨Ø± OpenAI (Ù…Ø¹ Ù…Ø­Ø§ÙˆÙ„Ø§Øª RETRY)
# ===============================
def extract_financial_data(file_bytes, file_name, file_type):
    """ÙŠØ³ØªØ¯Ø¹ÙŠ OpenAI Ù„ÙŠÙØ±Ø¬Ø¹ JSON Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø®Ø·Ø·. ÙŠØ¹ÙŠØ¯ dict Ø£Ùˆ None."""
    if not OPENAI_API_KEY:
        return None

    MAX_RETRIES = 3
    INITIAL_WAIT_SECONDS = 5

    mime_type = "application/pdf" if file_type.lower() == 'pdf' else f"image/{file_type.lower()}"

    # Ù†Ø¶Ø¹ Ø§Ù„Ù…Ù„Ù ÙƒÙ€ base64 Ø¶Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø³Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‚Ø¯ ÙŠÙƒÙˆÙ† ÙƒØ¨ÙŠØ±Ø§Ù‹ - Ù„ÙƒÙ† Ù†Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ Ø¢Ù„ÙŠØ© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù„Ù†Ø³Ø®ØªÙƒ)
    file_b64 = base64.b64encode(file_bytes).decode('utf-8')

    user_prompt = (
        "Ù‚Ù… Ø¨Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ù„ÙŠØ© Ø¥Ù„Ù‰ JSON Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø®Ø·Ø·ØŒ ÙˆØ£Ø¬Ø¨ ÙÙ‚Ø· Ø¨Ø§Ù„Ù€ JSON Ø¯ÙˆÙ† Ø£ÙŠ Ø´Ø±Ø­ Ø¥Ø¶Ø§ÙÙŠ.\n\n"
        f"Ø§Ù„Ù…Ø®Ø·Ø· (Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ†): {', '.join(REPORT_FIELDS_ARABIC)}\n\n"
        "Ù‚ÙˆØ§Ø¹Ø¯:\n"
        "- Ø¬Ù…ÙŠØ¹ Ø­Ù‚ÙˆÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ® ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¨ØµÙŠØºØ© YYYY/MM/DD Ø£Ùˆ 'ØºÙŠØ± Ù…ØªÙˆÙØ±'.\n"
        "- Ø¥Ù† Ù„Ù… ÙŠØ¸Ù‡Ø± Ø­Ù‚Ù„ ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¶Ø¹ 'ØºÙŠØ± Ù…ØªÙˆÙØ±'.\n"
        "- Ø­Ù‚Ù„ 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­ØªÙˆÙŠ Ø±Ù‚Ù…Ù‹Ø§ Ù…Ù† 1 Ø¥Ù„Ù‰ 11 Ø£Ùˆ 'ØºÙŠØ± Ù…ØªÙˆÙØ±'.\n\n"
        "Ø§Ù„Ø¢Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø±ÙÙ‚ (Base64). Ù„Ø§ ØªØ°ÙƒØ± Base64 ÙÙŠ Ø§Ù„Ù†Ø§ØªØ¬ØŒ Ø§Ø³ØªØ®Ø¯Ù…Ù‡ ÙÙ‚Ø· Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¥Ù† Ø£Ù…ÙƒÙ†:\n\n"
        f"FILE_NAME: {file_name}\nFILE_MIME: {mime_type}\nFILE_BASE64: (Ù…Ø¶Ù…Ù‘ÙÙ†)\n"
    )

    for attempt in range(MAX_RETRIES):
        try:
            response = client.responses.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": user_prompt}
                ],
                # Ù†Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¥Ø®Ø±Ø§Ø¬ JSON Ù†ØµÙŠØ› Ø³Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ù„Ø§Ø­Ù‚Ù‹Ø§
                max_tokens=4000,
                temperature=0.0
            )

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© (ÙŠØªÙˆÙ‚Ù Ø¹Ù„Ù‰ ÙˆØ§Ø¬Ù‡Ø© SDKØ› Ù‡Ù†Ø§ Ù†Ù‚Ø±Ø£ Ù…Ù† response)
            # Ø§Ù„Ø­Ù‚Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ù…ØªÙˆØ§ÙÙ‚ Ù…Ø¹ OpenAI Python SDK Ø§Ù„Ø­Ø¯ÙŠØ«: response.output_text Ø£Ùˆ Ø¯Ù…Ø¬ Ù…Ù† response.output
            try:
                output_text = response.output_text  # Ø¥Ù† ÙƒØ§Ù† Ù…ØªØ§Ø­Ù‹Ø§
            except Exception:
                # Fall back: Ø­Ø§ÙˆÙ„ Ø¬Ù…Ø¹ Ù†ØµÙˆØµ Ù…Ù† response.output Ø¥Ù† ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
                output_text = ""
                if hasattr(response, "output") and isinstance(response.output, list):
                    for item in response.output:
                        if isinstance(item, dict) and "content" in item:
                            # Ù‚Ø¯ ÙŠÙƒÙˆÙ† content Ù‚Ø§Ø¦Ù…Ø©
                            cont = item.get("content")
                            if isinstance(cont, list):
                                for c in cont:
                                    if c.get("type") == "output_text":
                                        output_text += c.get("text", "")
                            elif isinstance(cont, str):
                                output_text += cont

            # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ù†ØµÙ‹Ø§ØŒ Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… choices (Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¯ÙŠÙ…)
            if not output_text and hasattr(response, "choices"):
                try:
                    output_text = response.choices[0].message["content"]
                except Exception:
                    # Ø¢Ø®Ø± Ø­Ù„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ
                    output_text = str(response)

            # Ø§Ù„Ø¢Ù† Ù†Ø­Ø§ÙˆÙ„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ù…Ù† Ø§Ù„Ù†Øµ
            # Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù‚Ø¯ ØªØ±Ø¬Ø¹ JSON Ù…Ø¶Ù…Ù†Ù‹Ø§ Ø¯Ø§Ø®Ù„ Ù†ØµØ› Ù†Ø­Ø§ÙˆÙ„ Ø¥ÙŠØ¬Ø§Ø¯ Ø£ÙˆÙ„ Ù‚ÙˆØ³ Ù…Ø¹Ù‚ÙˆÙ
            json_text = output_text.strip()
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨Ø¯Ø§ÙŠØ© JSON
            start = json_text.find('{')
            end = json_text.rfind('}')
            if start != -1 and end != -1 and end > start:
                json_candidate = json_text[start:end+1]
            else:
                json_candidate = json_text

            extracted_data = {}
            try:
                extracted_data = json.loads(json_candidate)
            except Exception as e_json:
                # ÙØ´Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ => Ù†Ø±Ø¬Ù‘Ø¹ None Ø¨Ø¹Ø¯ ØªÙˆØ¶ÙŠØ­ ÙÙŠ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø³ØªØ±ÙŠÙ…Ù„ÙŠØª
                st.error(f"âŒ ÙØ´Ù„ ØªØ­ÙˆÙŠÙ„ Ù†Ø§ØªØ¬ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø¥Ù„Ù‰ JSON Ù„Ù„Ù…Ù„Ù {file_name}: {e_json}")
                st.info("Ù†Øµ Ø§Ù„Ù†Ø§ØªØ¬ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø£ÙˆÙ„ 1000 Ø­Ø±Ù):")
                st.code(json_text[:1000])
                return None

            # Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ: Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„Ø¥Ø¶Ø§ÙØ§Øª
            extracted_data = pre_process_data_fix_dates(extracted_data)
            extracted_data['Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù'] = file_name
            riyadh_tz = pytz.timezone('Asia/Riyadh')
            extracted_data['ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ'] = pd.Timestamp.now(tz=riyadh_tz).strftime("%Y-%m-%d %H:%M:%S")
            extracted_data['Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª'] = check_for_suspicion(extracted_data)

            # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ ÙƒÙ„ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
            for fld in REPORT_FIELDS_ARABIC:
                if fld not in extracted_data:
                    extracted_data[fld] = "ØºÙŠØ± Ù…ØªÙˆÙØ±"

            return extracted_data

        except Exception as e:
            is_last = (attempt == MAX_RETRIES - 1)
            wait_time = INITIAL_WAIT_SECONDS * (2 ** attempt)
            st.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø±Ù‚Ù… {attempt+1} ÙØ´Ù„Øª Ù„Ù…Ù„Ù {file_name}: {e}.")
            if not is_last:
                st.info(f"Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨Ø¹Ø¯ {wait_time} Ø«Ø§Ù†ÙŠØ©...")
                time.sleep(wait_time)
                continue
            else:
                st.error(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ù…Ù† {file_name} Ø¨Ø¹Ø¯ {MAX_RETRIES} Ù…Ø­Ø§ÙˆÙ„Ø§Øª.")
                return None


# ===============================
# ÙˆØ¸Ø§Ø¦Ù Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙˆÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
# ===============================
def create_final_report_from_db(records, column_names):
    import xlsxwriter
    if not records:
        st.warning("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªØµØ¯ÙŠØ±Ù‡Ø§.")
        return None

    df = pd.DataFrame(records, columns=column_names)
    df.insert(0, '#', range(1, len(df) + 1))

    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    sheet_name = 'Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ'
    df.to_excel(writer, sheet_name=sheet_name, index=False)

    workbook, worksheet = writer.book, writer.sheets[sheet_name]
    worksheet.right_to_left()
    col_format = workbook.add_format({'text_wrap': True, 'align': 'right', 'valign': 'top'})

    for i, col_name in enumerate(df.columns):
        if col_name in ['Ø³Ø¨Ø¨ Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡']:
            worksheet.set_column(i, i, 120, col_format)
        else:
            width = 25 if col_name in ["Ø§Ø³Ù… Ø§Ù„Ù…Ø´ØªØ¨Ù‡ Ø¨Ù‡", "Ø±Ù‚Ù… ØµØ§Ø­Ø¨ Ø§Ù„Ø¹Ù…Ù„/ Ø§Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ¬Ø§Ø±ÙŠ", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] else 18
            worksheet.set_column(i, i, width, col_format)

    writer.close()
    output.seek(0)
    return output.read()


def display_basic_stats():
    st.markdown("---")
    st.subheader("Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø© ğŸ“ˆ")
    report_data = fetch_all_reports()
    total_count = 0
    if report_data and report_data[0]:
        records, _ = report_data
        total_count = len(records)

    st.metric(label="Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª/Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", value=total_count)
    st.markdown("---")


# ===============================
# CSS ÙˆÙˆØ§Ø¬Ù‡Ø© Streamlit
# ===============================
st.markdown(
    """
    <style>
    .stApp { background-color: #f5f7fa; font-family: "Tajawal", sans-serif; }
    h1,h2,h3 { color: #1a3c6e !important; font-weight: 700 !important; }
    p, div, span { font-size: 16px !important; }
    .stButton button { background-color: #1a3c6e !important; color: white !important; border-radius: 10px !important; padding: 10px 25px !important; font-size: 17px !important; transition: 0.3s; }
    .stButton button:hover { background-color: #102649 !important; transform: scale(1.05); }
    .stDataFrame table { border-radius: 10px !important; }
    .dataframe tbody tr:nth-child(odd) { background-color: #eef2f7 !important; }
    .dataframe tbody tr:hover { background-color: #d7e3ff !important; }
    </style>
    """,
    unsafe_allow_html=True
)

# ===============================
# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
# ===============================
def main():
    st.set_page_config(layout="wide", page_title="Ø£Ø¯Ø§Ø© Ø§Ø³ØªØ®Ù„Ø§Øµ ÙˆØªÙ‚Ø§Ø±ÙŠØ± Ù…Ø§Ù„ÙŠØ©")
    st.title("ğŸ“„ Ù†Ø¸Ø§Ù… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
    st.markdown("---")

    # ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù† Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
    try:
        initialize_db()
    except OperationalError:
        st.error("âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ø°ÙˆÙ†Ø§Øª Ø§Ù„ÙƒØªØ§Ø¨Ø© Ù„Ù„Ù…Ø¬Ù„Ø¯.")

    if 'extracted_data_df' not in st.session_state:
        st.session_state['extracted_data_df'] = pd.DataFrame()

    uploaded_files = st.file_uploader(
        "ğŸ“¤ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª (pdf, png, jpg, jpeg) - ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø®ØªÙŠØ§Ø± Ø¹Ø¯Ø© Ù…Ù„ÙØ§Øª",
        type=["pdf", "png", "jpg", "jpeg"],
        accept_multiple_files=True
    )

    if uploaded_files:
        all_extracted_data = []

        if st.button("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"):
            total_files = len(uploaded_files)
            progress_bar = st.progress(0)
            status_text = st.empty()
            processed_count = 0

            status_text.info(f"â³ Ø¨Ø¯Ø¡ Ø§Ø³ØªØ®Ù„Ø§Øµ {total_files} Ù…Ù„ÙØ§Øª Ø¨Ø§Ù„ØªØ³Ù„Ø³Ù„. Ø³ÙŠØ£Ø®Ø° ÙƒÙ„ Ù…Ù„Ù Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù„Ø§Ø²Ù… Ù„Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ...")

            for i, uploaded_file in enumerate(uploaded_files):
                file_bytes, file_name = uploaded_file.read(), uploaded_file.name
                file_type = file_name.split('.')[-1].lower()

                status_text.info(f"â³ Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù **{file_name}** ({i+1} Ù…Ù† {total_files}).")
                data = extract_financial_data(file_bytes, file_name, file_type)

                if data:
                    all_extracted_data.append(data)
                    st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† **{file_name}** Ø¨Ù†Ø¬Ø§Ø­.")
                else:
                    st.warning(f"âš ï¸ ÙØ´Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† **{file_name}**. Ø±Ø§Ø¬Ø¹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø®Ø·Ø£ Ø£Ø¹Ù„Ø§Ù‡.")

                processed_count += 1
                progress_bar.progress(processed_count / total_files)

            if all_extracted_data:
                status_text.success(f"âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ({len(all_extracted_data)} Ù…Ù„ÙØ§Øª).")
                new_df = pd.DataFrame(all_extracted_data)
                display_cols = ["Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª", "Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù", "ÙˆÙ‚Øª Ø§Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ"] + REPORT_FIELDS_ARABIC
                new_df = new_df.reindex(columns=display_cols, fill_value='ØºÙŠØ± Ù…ØªÙˆÙØ±')
                st.session_state['extracted_data_df'] = pd.concat([st.session_state['extracted_data_df'], new_df], ignore_index=True)
            else:
                status_text.error("âŒ ÙØ´Ù„ Ø§Ø³ØªØ®Ù„Ø§Øµ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª.")
                progress_bar.empty()

    # Ø¬Ø¯ÙˆÙ„ Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ø¯ÙŠÙ„
    if not st.session_state['extracted_data_df'].empty:
        st.subheader("âœï¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© (Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„)")

        if st.button("ğŸ’¡ Ø§Ø³ØªØ®Ø±Ø¬ Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø©"):
            temp_df = st.session_state['extracted_data_df'].copy()
            if 'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)' in temp_df.columns:
                temp_df.drop(columns=['Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)'], inplace=True, errors='ignore')

            def get_delala_description(row):
                delala_num = str(row.get('Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©', 'ØºÙŠØ± Ù…ØªÙˆÙØ±')).strip()
                try:
                    num = int(delala_num)
                    return f"({num}) {DELALAT_MAPPING.get(num, 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© ØºÙŠØ± ØµØ­ÙŠØ­')}"
                except ValueError:
                    return delala_num

            if 'Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©' in temp_df.columns:
                temp_df.insert(temp_df.columns.get_loc('Ø±Ù‚Ù… Ø§Ù„Ø¯Ù„Ø§Ù„Ø©') + 1,
                               'Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)',
                               temp_df.apply(get_delala_description, axis=1))
            st.session_state['extracted_data_df'] = temp_df
            st.rerun()

        edited_df = st.data_editor(
            st.session_state['extracted_data_df'],
            use_container_width=True,
            num_rows="dynamic"
        )

        st.markdown("---")
        if st.button("ğŸ’¾ ØªØ£ÙƒÙŠØ¯ ÙˆØ­ÙØ¸ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
            saved_count = 0
            total_rows = len(edited_df)
            status_placeholder = st.empty()
            for index, row in edited_df.iterrows():
                row_data = dict(row)
                # Ø­Ø°Ù Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¤Ù‚ØªØ©
                row_data.pop('Ù…Ø¤Ø´Ø± Ø§Ù„ØªØ´ØªØª', None)
                row_data.pop('Ù†Øµ Ø§Ù„Ø¯Ù„Ø§Ù„Ø© Ø§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©)', None)
                if save_to_db(row_data):
                    saved_count += 1
                else:
                    status_placeholder.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„ Ø±Ù‚Ù… {index + 1}.")
                    break

            if saved_count == total_rows:
                status_placeholder.success(f"âœ… ØªÙ… Ø­ÙØ¸ {saved_count} Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
                st.session_state['extracted_data_df'] = pd.DataFrame()
                st.rerun()
            elif saved_count > 0:
                status_placeholder.warning(f"âš ï¸ ØªÙ… Ø­ÙØ¸ {saved_count} ÙÙ‚Ø·. Ø±Ø§Ø¬Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡.")
            else:
                status_placeholder.error("âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª.")

    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØªØµØ¯ÙŠØ±
    display_basic_stats()

    st.markdown("---")
    st.subheader("ğŸ“Š ØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
    if st.button("â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Excel Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"):
        report_data = fetch_all_reports()
        if report_data and report_data[0] is not None:
            records, column_names = report_data
            with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©..."):
                excel_data_bytes = create_final_report_from_db(records, column_names)
            if excel_data_bytes:
                st.download_button(
                    "â¬‡ï¸ Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„",
                    data=excel_data_bytes,
                    file_name="Final_Database_Report.xlsx",
                    mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
            else:
                st.warning("Ù„Ù… ÙŠØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Excel. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ±Ø¬Ø¹Ø© ÙØ§Ø±ØºØ©.")
        else:
            st.error("ÙØ´Ù„ ÙÙŠ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø³Ø¬Ù„Ø§Øª.")

if __name__ == "__main__":
    main()
